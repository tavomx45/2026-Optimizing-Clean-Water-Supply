{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b92d672a-a1ff-4806-9dce-5f8c9a4f051b",
      "metadata": {
        "name": "cell1",
        "codeCollapsed": true
      },
      "source": "# Water Quality Prediction: Benchmark Notebook "
    },
    {
      "cell_type": "markdown",
      "id": "173e8dca-8e21-478c-b9d8-8162214025ef",
      "metadata": {
        "name": "cell2",
        "codeCollapsed": true
      },
      "source": "## Challenge Overview"
    },
    {
      "cell_type": "markdown",
      "id": "0d38782b-973e-4f63-83b3-3e556abae629",
      "metadata": {
        "name": "cell3",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "Welcome to the EY AI & Data Challenge 2026!  \nThe objective of this challenge is to build a robust **machine learning model** capable of predicting water quality across various river locations in South Africa. In addition to accurate predictions, the model should also identify and emphasize the key factors that significantly influence water quality.\n\nParticipants will be provided with a dataset containing three water quality parameters — **Total Alkalinity**, **Electrical Conductance**, and **Dissolved Reactive Phosphorus** — collected between 2011 and 2015 from approximately 200 river locations across South Africa. Each data point includes the geographic coordinates (latitude and longitude) of the sampling site, the date of collection, and the corresponding water quality measurements.\n\nUsing this dataset, participants are expected to build a machine learning model to predict water quality parameters for a separate validation dataset, which includes locations from different regions not present in the training data. The challenge also encourages participants to explore feature importance and provide insights into the factors most strongly associated with variations in water quality.\n\nThis challenge is designed for participants with varying levels of experience in data science, remote sensing, and environmental analytics. It offers a valuable opportunity to apply machine learning techniques to real-world environmental data and contribute to advancing water quality monitoring using artificial intelligence."
    },
    {
      "cell_type": "markdown",
      "id": "1ea5ca99-0ab8-4117-8bf1-991714e656be",
      "metadata": {
        "name": "cell4",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "**About the Notebook:**  "
    },
    {
      "cell_type": "markdown",
      "id": "86be35cd-7ec3-4697-b476-efb378803e53",
      "metadata": {
        "name": "cell5",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "In this notebook, we demonstrate a basic workflow that serves as a foundation for the challenge. The model has been developed to predict **water quality parameters** using features derived from the **Landsat** and **TerraClimate** datasets. Specifically, four spectral bands — **SWIR22** (Shortwave Infrared 2), **NIR** (Near Infrared), **Green**, and **SWIR16** (Shortwave Infrared 1) — were utilized from Landsat, along with derived spectral indices such as **NDMI** (Normalized Difference Moisture Index) and **MNDWI** (Modified Normalized Difference Water Index). In addition, the **PET** (Potential Evapotranspiration) variable was incorporated from the **TerraClimate** dataset to account for climatic influences on water quality.\n\nThe dataset spans a five-year period from **2011 to 2015**. Using **API-based data extraction** methods, both Landsat and TerraClimate features were retrieved directly from the [Microsoft Planetary Computer portal](https://planetarycomputer.microsoft.com).\n\nThese combined spectral, index-based, and climatic features were used as predictors in a regression model to estimate three key water quality parameters: **Total Alkalinity (TA)**, **Electrical Conductance (EC)**, and **Dissolved Reactive Phosphorus (DRP)**.\n\nPlease note that this notebook serves only as a starting point. Several assumptions were made during the data extraction and model development process, which you may find opportunities to improve upon. Participants are encouraged to explore additional features, enhance preprocessing techniques, or experiment with different regression algorithms to optimize predictive performance."
    },
    {
      "cell_type": "markdown",
      "id": "57447c9d-ceca-4a26-8066-2dca61e0e224",
      "metadata": {
        "name": "cell6",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Load In Dependencies\nThe following code installs the required Python libraries (found in the requirements.txt file) in the Snowflake environment to allow successful execution of the remaining notebook code. After running this code for the first time, it is required to “restart” the kernal so the Python libraries are available in the environment. This is done by selecting the “Connected” menu above the notebook (next to “Run all”) and selecting the “restart kernal” link. Subsequent runs of the notebook do not require this “restart” process."
    },
    {
      "cell_type": "code",
      "id": "7d7871c0-d5f3-45da-a289-3d19db67bf15",
      "metadata": {
        "language": "python",
        "name": "cell58"
      },
      "source": "!pip install uv\n!uv pip install  -r requirements.txt",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "b53ef74f-52ba-4c63-b412-2f4432408d04",
      "metadata": {
        "language": "python",
        "name": "cell8",
        "codeCollapsed": false
      },
      "source": "import snowflake\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n# Suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Data manipulation and analysis\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display\n\n# Multi-dimensional arrays and datasets (e.g., NetCDF, Zarr)\nimport xarray as xr\n\n# Geospatial raster data handling with CRS support\nimport rioxarray as rxr\n\n# Raster operations and spatial windowing\nimport rasterio\nfrom rasterio.windows import Window\n\n# Feature preprocessing and data splitting\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom scipy.spatial import cKDTree\n\n# Machine Learning\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n\n# Planetary Computer tools for STAC API access and authentication\nimport pystac_client\nimport planetary_computer as pc\nfrom odc.stac import stac_load\nfrom pystac.extensions.eo import EOExtension as eo\n\nfrom datetime import date\nfrom tqdm import tqdm\nimport os ",
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "id": "fdfcbb20-8dff-401a-9f55-ed5d08eb6b60",
      "metadata": {
        "name": "cell9",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Response Variable"
    },
    {
      "cell_type": "markdown",
      "id": "401e1bce-f161-4d24-9f6b-a60778c39585",
      "metadata": {
        "name": "cell10",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "Before building the model, we first load the **water quality training dataset**. The curated dataset contains samples collected from various monitoring stations across the study region. Each record includes the geographical coordinates (Latitude and Longitude), the sample collection date, and the corresponding **measured values** for the three key water quality parameters — **Total Alkalinity (TA)**, **Electrical Conductance (EC)**, and **Dissolved Reactive Phosphorus (DRP)**."
    },
    {
      "cell_type": "code",
      "id": "892acc46-4840-489a-8c69-ecf4123d2a31",
      "metadata": {
        "language": "python"
      },
      "source": "Water_Quality_df = pd.read_csv(\"water_quality_training_dataset.csv\")\ndisplay(Water_Quality_df.head(5))",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "99c4a563-c697-45d5-bc83-bfc56fd0341e",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "MY CODE:\nREAD DATA FROM SNOWFLAKE TABLES"
    },
    {
      "cell_type": "code",
      "id": "5ba5cd03-4217-46a4-b3aa-4606bfaa4f2e",
      "metadata": {
        "language": "sql",
        "resultVariableName": "dataframe_1"
      },
      "source": "%%sql -r dataframe_1\nUSE DATABASE OPTIMIZING_CLEAN_WATER_SUPPLY",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "fd15e843-51df-45b2-96df-7f3081f44093",
      "metadata": {
        "language": "python"
      },
      "source": "train_df = session.table('FEATURES.FEATURE_MART_TRAIN_IMPUTED').to_pandas()\ndisplay(train_df.head())",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5791a746-27c1-49d1-b034-f51c85b0203d",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "train_df.columns",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "1ac87b43-019d-4aa4-bb4b-62b40cc6cda2",
      "metadata": {
        "name": "cell12",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Predictor Variables"
    },
    {
      "cell_type": "markdown",
      "id": "459bbd80-887c-4c1f-83f4-3d31ffc40551",
      "metadata": {
        "name": "cell13",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "Now that we have our water quality dataset, the next step is to gather the predictor variables from the **Landsat** and **TerraClimate** datasets. In this notebook, we demonstrate how to **load previously extracted satellite and climate data** from separate files, rather than performing the extraction directly, which allows for a smoother and faster experience. Participants can refer to the dedicated extraction notebooks—one for Landsat and another for TerraClimate—to understand how the data was retrieved and processed, and they can also generate their own output CSV files if needed. Using these pre-extracted CSV files, this notebook focuses on loading the predictor features and running the subsequent analysis and model training efficiently.\n\nFor more detailed guidance on the original data extraction process, you can review the Landsat and TerraClimate example notebooks available on the Planetary Computer portal:\n\n- [Landsat-c2-l2 - Example-Notebook](https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2#Example-Notebook)  \n- [Terraclimate - Example-Notebook](https://planetarycomputer.microsoft.com/dataset/terraclimate#Example-Notebook)\n\nWe have used selected spectral bands — **SWIR22** (Shortwave Infrared 2), **NIR** (Near Infrared), **Green**, and **SWIR16** (Shortwave Infrared 1) — and computed key spectral indices such as **NDMI** (Normalized Difference Moisture Index) and **MNDWI** (Modified Normalized Difference Water Index). These features capture surface moisture, vegetation, and water content characteristics that influence water quality variability.\n\nIn addition to Landsat features, we also incorporated the **Potential Evapotranspiration (PET)** variable from the **TerraClimate** dataset, which provides high-resolution global climate data. The PET feature captures the atmospheric demand for moisture, representing climatic conditions such as temperature, humidity, and radiation that influence surface water evaporation and thus affect water quality parameters.\n\nThe predictor features include:\n\n- **SWIR22** – Sensitive to surface moisture and turbidity variations in water bodies.  \n- **NIR** – Helps in identifying vegetation and suspended matter in water.  \n- **Green** – Useful for detecting water color and surface reflectance changes.  \n- **SWIR16** – Provides information on surface dryness and sediment concentration.  \n- **NDMI** – Derived from NIR and SWIR16, indicates moisture and vegetation–water interaction.  \n- **MNDWI** – Derived from Green and SWIR22, effective for distinguishing open water areas and reducing built-up noise.  \n- **PET** – Extracted from the TerraClimate dataset, represents potential evapotranspiration influencing hydrological and water quality dynamics."
    },
    {
      "cell_type": "markdown",
      "id": "cced81f1-3b77-4a69-ac48-9d02cc12c647",
      "metadata": {
        "name": "cell14",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### **Tip 1**\n\nParticipants are encouraged to experiment with different combinations of **Landsat** bands or even include data from other public satellite data sources. By creating mathematical combinations of bands, you can derive various spectral indices that capture surface and environmental characteristics."
    },
    {
      "cell_type": "markdown",
      "id": "83a0c7e8-9471-4a09-9ac4-6a5b5f0703bd",
      "metadata": {
        "name": "cell15",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Loading Pre-Extracted Landsat Data\n\nIn this notebook, we **load previously extracted Landsat data** from CSV files generated in a separate extraction notebook. This approach ensures a smoother and faster workflow, allowing participants to focus on data analysis and model development without waiting for time-consuming data retrieval.\n\nParticipants are expected to generate their own data extraction CSV files by running the dedicated Landsat extraction notebook. These CSV files can then be used here to smoothly run this benchmark notebook. Participants can refer to the extraction notebook to understand the API-based process, including how individual bands and indices like **NDMI** were computed. Using these pre-extracted CSV files simplifies preprocessing and is ideal for large-scale environmental and water quality analysis."
    },
    {
      "cell_type": "markdown",
      "id": "bfe34327-f165-452c-98ef-3df67b6ed550",
      "metadata": {
        "name": "cell16",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### **Tip 2**\n\nIn the data extraction process (performed in the dedicated extraction notebooks), a 100 m focal buffer was applied around each sampling location rather than using a single point. Participants may explore creating different focal buffers around the locations (e.g., 50 m, 150 m, etc.) during extraction. For example, if a 50 m buffer was used for “Band 2”, the extracted CSV values would reflect the average of Band 2 within 50 meters of each location. This approach can help reduce errors associated with spatial autocorrelation."
    },
    {
      "cell_type": "code",
      "id": "5c250c49-d6ed-42f7-ad90-b2f619de0027",
      "metadata": {
        "language": "python"
      },
      "source": "landsat_train_features = pd.read_csv(\"landsat_features_training.csv\")\ndisplay(landsat_train_features.head(5))",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "61676d8d-7141-4682-9687-850e56e3ef28",
      "metadata": {
        "language": "python"
      },
      "source": "# If NDMI and MNDWI columns are of type object, convert them to float\nlandsat_train_features['NDMI'] = landsat_train_features['NDMI'].astype(float)\nlandsat_train_features['MNDWI'] = landsat_train_features['MNDWI'].astype(float)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "8ce0ed5d-32c0-48f9-863c-ef84bad110d2",
      "metadata": {
        "name": "cell18",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Loading Pre-Extracted TerraClimate Data\n\nIn this notebook, we **load previously extracted TerraClimate data** from CSV files generated in a dedicated extraction notebook. This approach ensures a smoother and faster workflow, allowing participants to focus on data analysis and model development without waiting for time-consuming data retrieval.\n\nParticipants are expected to generate their own data extraction CSV files by running the dedicated TerraClimate extraction notebook. These CSV files can then be used here to smoothly run this benchmark notebook. Participants can refer to the extraction notebook to understand the API-based process, including how climate variables such as **Potential Evapotranspiration (PET)** were extracted. Using these pre-extracted CSV files ensures consistent, automated retrieval of high-resolution climate data that can be easily integrated with satellite-derived features for comprehensive environmental and hydrological analysis."
    },
    {
      "cell_type": "code",
      "id": "1862bd48-8134-477a-bcf5-314ac04b2048",
      "metadata": {
        "language": "python"
      },
      "source": "Terraclimate_df = pd.read_csv(\"terraclimate_features_training.csv\")\ndisplay(Terraclimate_df.head(5))",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "475de826-a08c-4ea1-bbfc-5e9a3240ab22",
      "metadata": {
        "name": "cell20",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Joining the Predictor Variables and Response Variables\n\nNow that we have extracted our predictor variables, we need to join them with the response variables. We use the **combine_two_datasets** function to merge the predictor variables and response variables. The **concat** function from pandas is particularly useful for this step."
    },
    {
      "cell_type": "code",
      "id": "7b42801e-e7b9-4b17-b4e4-f65fd971decc",
      "metadata": {
        "language": "python",
        "name": "cell21"
      },
      "source": "# Combine two datasets vertically (along columns) using pandas concat function.\ndef combine_two_datasets(dataset1,dataset2,dataset3):\n    '''\n    Returns a  vertically concatenated dataset.\n    Attributes:\n    dataset1 - Dataset 1 to be combined \n    dataset2 - Dataset 2 to be combined\n    '''\n    \n    data = pd.concat([dataset1,dataset2,dataset3], axis=1)\n    data = data.loc[:, ~data.columns.duplicated()]\n    return data",
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "id": "c75dffde-a8e3-4a6e-bbab-bf0d8aac7bfe",
      "metadata": {
        "language": "python",
        "name": "cell22",
        "codeCollapsed": false
      },
      "source": "# Combining ground data and final data into a single dataset.\nwq_data = combine_two_datasets(Water_Quality_df, landsat_train_features, Terraclimate_df)\ndisplay(wq_data.head(5))",
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "id": "c4573656-100c-49e7-b3bb-536e0a6290ac",
      "metadata": {
        "name": "cell23",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Handling Missing Values\n\nBefore model training, missing values in the dataset were carefully handled to ensure data consistency and prevent model bias. Numerical columns were imputed using their median values, maintaining the overall data distribution while minimizing the impact of outliers."
    },
    {
      "cell_type": "code",
      "id": "de7372e4-26c6-4bd8-9d7a-39bc35b01a14",
      "metadata": {
        "language": "python",
        "name": "cell24"
      },
      "source": "wq_data = wq_data.fillna(wq_data.median(numeric_only=True))\nwq_data.isna().sum()",
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "id": "560a997d-ec88-4ae0-b540-44cd3e5f6cf2",
      "metadata": {
        "name": "cell25",
        "codeCollapsed": true
      },
      "source": "## Model Building"
    },
    {
      "cell_type": "markdown",
      "id": "8e9f7c65-b3a1-405b-b912-cef4e5157bce",
      "metadata": {
        "name": "cell26",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "Now let us select the columns required for our model-building exercise. We will consider only **SWIR22**, **NDMI**, and **MNDWI** from the Landsat data, and **PET** from the TerraClimate dataset as our predictor variables. It does not make sense to use latitude and longitude as predictor variables, as they do not have any direct impact on predicting the water quality parameters."
    },
    {
      "cell_type": "code",
      "id": "35381365-adf1-4702-a99d-5cec95812ff9",
      "metadata": {
        "language": "python",
        "name": "cell27"
      },
      "source": "# Retaining only the columns for swir22, NDMI, MNDWI, pet, Total Alkalinity, Electrical Conductance and Dissolved Reactive Phosphorus Index in the dataset.\nwq_data = wq_data[['swir22','NDMI','MNDWI','pet', 'Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus']]",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "80cabfc4-d877-4d80-966d-c0e934adb447",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "MY CODE: REPLACE FEATURES AND TARGET VARIABLES"
    },
    {
      "cell_type": "code",
      "id": "f355e34a-a6b6-4857-baae-1cd5a2998396",
      "metadata": {
        "language": "python"
      },
      "source": "TARGETS = [\"TOTAL_ALKALINITY\", \"ELECTRICAL_CONDUCTANCE\", \"DISSOLVED_REACTIVE_PHOSPHORUS\"]\n\nFEATURES = [\n    \"SWIR22\", \"NDMI\", \"MNDWI\", \"PET\",\n    \"SIN_DOY\", \"COS_DOY\", \"NIR\", \"GREEN\", \"SWIR16\"\n]\n\nX = train_df[FEATURES]\ny_TA  = train_df[\"TOTAL_ALKALINITY\"]\ny_EC  = train_df[\"ELECTRICAL_CONDUCTANCE\"]\ny_DRP = train_df[\"DISSOLVED_REACTIVE_PHOSPHORUS\"]",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "f56f994c-0b88-4d19-8426-3fb73c71e2b5",
      "metadata": {
        "name": "cell28",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### **Tip 3**\n\nWe are developing individual models for each water quality parameter using a common set of features: **SWIR22**, **NDMI**, **MNDWI**, and **PET**. However, participants are encouraged to experiment with different feature combinations to build more robust machine learning models."
    },
    {
      "cell_type": "markdown",
      "id": "1e241de9-35e2-4fa6-9bba-2d5456af838a",
      "metadata": {
        "name": "cell29",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Helper Functions\n\n### Train and Test Split\nWe will now split the data into 70% training data and 30% test data. Scikit-learn (sklearn) is a robust library for machine learning in Python. The `model_selection` module in scikit-learn provides the `train_test_split` function, which can be used for this purpose.\n\n### Feature Scaling\nBefore initiating model training, we may need to perform various data preprocessing steps. Here, we demonstrate scaling of the variables **SWIR22**, **NDMI**, **MNDWI**, and **PET** using StandardScaler.\n\nFeature scaling is an essential preprocessing step for numerical features. Many machine learning algorithms—such as gradient descent methods, KNN, and linear or logistic regression—require scaling to achieve optimal performance. Scikit-learn provides several scaling utilities. In this notebook, we use **StandardScaler**, which transforms the data so that each feature has a mean of 0 and a standard deviation of 1.\n\n### Model Training\nNow that we have the data in a format suitable for machine learning, we can begin training our models. In this demonstration notebook, we build three separate regression models—one for each target water quality parameter: **Total Alkalinity**, **Electrical Conductance**, and **Dissolved Reactive Phosphorus**. Each model is trained independently to capture the unique relationships between the satellite-derived features and each water quality parameter.\n\nWe use the **Random Forest Regressor** from the scikit-learn library for model training. Scikit-learn offers a wide range of regression algorithms, along with powerful parameter tuning and customization options.\n\nFor model training, the predictor variables (e.g., SWIR22, NDMI, MNDWI, and PET) are stored in an array `X`, and the response variable (one of the water quality parameters) is stored in an array `Y`. Note that the response variable should not be included in `X`. Also, latitude, longitude, and sample date are excluded from the predictor variables since they serve only as spatial and temporal references.\n\n### Model Evaluation\nAfter training the models for the three water quality parameters, the next step is to evaluate their performance. Each regression model—Total Alkalinity, Electrical Conductance, and Dissolved Reactive Phosphorus—is assessed using:\n\n- **R² Score**: Measures how well the model explains the variance in the observed values.  \n- **RMSE (Root Mean Square Error)**: Quantifies the average magnitude of prediction errors.\n\nTogether, these metrics help determine how effectively each model captures variations in water quality across locations and sampling dates. Scikit-learn provides built-in functions to compute both metrics. Participants may also explore additional evaluation techniques or custom metrics to enhance model assessment."
    },
    {
      "cell_type": "markdown",
      "id": "ad8e06d5-10a6-419a-b096-52c6f0566e1f",
      "metadata": {
        "name": "cell30",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### **Tip 4**\n\nThere are many data preprocessing methods available that may help improve model performance. Participants are encouraged to explore various preprocessing techniques as well as different machine learning algorithms to build a more robust model."
    },
    {
      "cell_type": "code",
      "id": "c7e68f6e-1679-467f-803c-e819d654bbab",
      "metadata": {
        "language": "python",
        "name": "cell31"
      },
      "source": "def split_data(X, y, test_size=0.3, random_state=42):\n    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n\ndef scale_data(X_train, X_test):\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    return X_train_scaled, X_test_scaled, scaler\n\ndef train_model(X_train_scaled, y_train):\n    model = RandomForestRegressor(n_estimators=100, random_state=42)\n    model.fit(X_train_scaled, y_train)\n    return model\n\ndef evaluate_model(model, X_scaled, y_true, dataset_name=\"Test\"):\n    y_pred = model.predict(X_scaled)\n    r2 = r2_score(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    print(f\"\\n{dataset_name} Evaluation:\")\n    print(f\"R²: {r2:.3f}\")\n    print(f\"RMSE: {rmse:.3f}\")\n    return y_pred, r2, rmse",
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "id": "39cec372-283e-404a-a989-714969c53b0d",
      "metadata": {
        "name": "cell32",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Model Workflow (Pipeline)\n\nThe complete model development process follows a structured pipeline to ensure consistency, reproducibility, and clarity. Each stage in the workflow is modularized into independent functions that can be reused for different water quality parameters. This modular approach streamlines the process and makes the workflow easily adaptable to new datasets or parameters in the future.\n\nThe pipeline automates the sequence of steps — from data preparation to evaluation — for each target parameter. The same set of predictor variables is used, while the response variable changes for each of the three targets: *Total Alkalinity (TA)*, *Electrical Conductance (EC)*, and *Dissolved Reactive Phosphorus (DRP)*. By maintaining a consistent framework, comparisons across models remain fair and interpretable."
    },
    {
      "cell_type": "code",
      "id": "40808f99-8014-4746-91ae-5b64c61e04a7",
      "metadata": {
        "language": "python",
        "name": "cell33"
      },
      "source": "def run_pipeline(X, y, param_name=\"Parameter\"):\n    print(f\"\\n{'='*60}\")\n    print(f\"Training Model for {param_name}\")\n    print(f\"{'='*60}\")\n    \n    # Split data\n    X_train, X_test, y_train, y_test = split_data(X, y)\n    \n    # Scale\n    X_train_scaled, X_test_scaled, scaler = scale_data(X_train, X_test)\n    \n    # Train\n    model = train_model(X_train_scaled, y_train)\n    \n    # Evaluate (in-sample)\n    y_train_pred, r2_train, rmse_train = evaluate_model(model, X_train_scaled, y_train, \"Train\")\n    \n    # Evaluate (out-sample)\n    y_test_pred, r2_test, rmse_test = evaluate_model(model, X_test_scaled, y_test, \"Test\")\n    \n    # Return summary\n    results = {\n        \"Parameter\": param_name,\n        \"R2_Train\": r2_train,\n        \"RMSE_Train\": rmse_train,\n        \"R2_Test\": r2_test,\n        \"RMSE_Test\": rmse_test\n    }\n    return model, scaler, pd.DataFrame([results])",
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "id": "1783a30e-ee66-4c50-a957-b67296e9328c",
      "metadata": {
        "name": "cell34",
        "codeCollapsed": true
      },
      "source": "### Model Training and Evaluation for Each Parameter"
    },
    {
      "cell_type": "markdown",
      "id": "ed5f39fd-a577-4eff-9fa5-caa9d7f2fcda",
      "metadata": {
        "name": "cell35",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "In this step, we apply the complete modeling pipeline to each of the three selected water quality parameters — Total Alkalinity, Electrical Conductance, and Dissolved Reactive Phosphorus. The input feature set (`X`) remains the same across all three models, while the target variable (`y`) changes for each parameter. \n\nFor every parameter, the `run_pipeline()` function is executed, which handles data preprocessing, model training, and both in-sample and out-of-sample evaluation. This ensures a consistent workflow and allows for a fair comparison of model performance across different water quality indicators."
    },
    {
      "cell_type": "code",
      "id": "d2d5f62b-585c-45e0-8fa9-73a5fa1248f8",
      "metadata": {
        "language": "python",
        "name": "cell36"
      },
      "source": "X = wq_data.drop(columns=['Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus'])\n\ny_TA = wq_data['Total Alkalinity']\ny_EC = wq_data['Electrical Conductance']\ny_DRP = wq_data['Dissolved Reactive Phosphorus']\n\nmodel_TA, scaler_TA, results_TA = run_pipeline(X, y_TA, \"Total Alkalinity\")\nmodel_EC, scaler_EC, results_EC = run_pipeline(X, y_EC, \"Electrical Conductance\")\nmodel_DRP, scaler_DRP, results_DRP = run_pipeline(X, y_DRP, \"Dissolved Reactive Phosphorus\")",
      "outputs": [],
      "execution_count": 11
    },
    {
      "id": "c98b286f-6798-4c9d-a7ac-815d4570b391",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "model_TA, scaler_TA, results_TA = run_pipeline(X, y_TA, \"TOTAL_ALKALINITY\")\nmodel_EC, scaler_EC, results_EC = run_pipeline(X, y_EC, \"ELECTRICAL_CONDUCTANCE\")\nmodel_DRP, scaler_DRP, results_DRP = run_pipeline(X, y_DRP, \"DISSOLVED_REACTIVE_PHOSPHORUS\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "644a854c-a8af-411e-b5af-e78d064d80a1",
      "metadata": {
        "name": "cell37",
        "codeCollapsed": true
      },
      "source": "### Model Performance Summary"
    },
    {
      "cell_type": "markdown",
      "id": "23b4c7a8-c192-469f-8a18-972f4900da2b",
      "metadata": {
        "name": "cell38",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "After training and evaluating the models for each water quality parameter, the individual performance metrics are combined into a single summary table. This table consolidates the R² and RMSE values for both in-sample and out-of-sample evaluations, enabling an easy comparison of model performance across Total Alkalinity, Electrical Conductance, and Dissolved Reactive Phosphorus. \n\nSuch a summary provides a quick overview of how well each model captures the variability in each parameter and highlights any differences in predictive accuracy."
    },
    {
      "cell_type": "code",
      "id": "c7f3a047-a05c-4369-8a84-5b287f1ff272",
      "metadata": {
        "language": "python",
        "name": "cell39"
      },
      "source": "results_summary = pd.concat([results_TA, results_EC, results_DRP], ignore_index=True)\nresults_summary",
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "id": "b5277b08-d7bc-4b7c-91bf-26fa19795f56",
      "metadata": {
        "name": "cell41",
        "codeCollapsed": true
      },
      "source": "## Submission"
    },
    {
      "cell_type": "markdown",
      "id": "f59c5dde-8a39-4e16-bdd9-93ce024850d2",
      "metadata": {
        "name": "cell42",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "Once you are satisfied with your model’s performance, you can proceed to make predictions for unseen data. To do this, use your trained model to estimate the concentrations of the target water quality parameters — Total Alkalinity, Electrical Conductance, and Dissolved Reactive Phosphorus — for a set of test locations provided in the **Submission_template.csv** file. \n\nThe predicted results can then be uploaded to the challenge platform for evaluation."
    },
    {
      "id": "512de6e7-7e9e-47ce-9b76-58cbc85e9229",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "MY CODE: READ SUBMISSION FROM TABLES"
    },
    {
      "id": "d897eb07-85c9-4841-a80a-f32de1481035",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "sub_feat = session.table(\"FEATURES.FEATURE_MART_SUBMISSION_IMPUTED\").to_pandas()\nsub_template = session.table(\"RAW.SUBMISSION_TEMPLATE\").to_pandas()\n\ndisplay(sub_feat.head())\ndisplay(sub_template.head())",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "1475b7c2-6562-4274-9bd6-98b305010351",
      "metadata": {
        "language": "python"
      },
      "source": "test_file = pd.read_csv(\"submission_template.csv\")\ndisplay(test_file.head(5))",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "36e85fe2-7570-432e-b1f2-bc16dda08ab4",
      "metadata": {
        "language": "python"
      },
      "source": "landsat_val_features = pd.read_csv(\"landsat_features_validation.csv\")\ndisplay(landsat_val_features.head(5))",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "48e53ead-e1b6-4d7d-93bb-12505fbb2ead",
      "metadata": {
        "language": "python"
      },
      "source": "Terraclimate_val_df = pd.read_csv(\"terraclimate_features_validation.csv\")\ndisplay(Terraclimate_val_df.head(5))",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "1feacaed-272c-4812-8c14-d2bd6a8d48f1",
      "metadata": {
        "name": "cell44",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "Similarly, participants can use the **Landsat** and **TerraClimate** data extraction demonstration notebooks to produce feature CSVs for their **validation** data. For convenience, we have already computed and saved example validation outputs as `landsat_features_val_V3.csv` and `Terraclimate_val_df_v3.csv`. \n\nParticipants should save their own extracted files in the same format and column schema; doing so will allow this benchmark notebook to load the validation features directly and run smoothly."
    },
    {
      "cell_type": "code",
      "id": "d1dabb48-7f82-4acf-b509-21cc15a5a4e0",
      "metadata": {
        "language": "python",
        "name": "cell47",
        "codeCollapsed": false
      },
      "source": "#Consolidate all the extracted bands and features in a single dataframe\nval_data = pd.DataFrame({\n    'Longitude': landsat_val_features['Longitude'].values,\n    'Latitude': landsat_val_features['Latitude'].values,\n    'Sample Date': landsat_val_features['Sample Date'].values,\n    'nir': landsat_val_features['nir'].values,\n    'green': landsat_val_features['green'].values,\n    'swir16': landsat_val_features['swir16'].values,\n    'swir22': landsat_val_features['swir22'].values,\n    'NDMI': landsat_val_features['NDMI'].values,\n    'MNDWI': landsat_val_features['MNDWI'].values,\n    'pet': Terraclimate_val_df['pet'].values,\n})",
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "id": "5c41d268-0657-490b-94f3-8ffeb67c2265",
      "metadata": {
        "language": "python",
        "name": "cell48",
        "codeCollapsed": false
      },
      "source": "# Impute the missing values\nval_data = val_data.fillna(val_data.median(numeric_only=True))",
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "id": "3126bf77-fb54-4609-a09c-8e36b496d108",
      "metadata": {
        "language": "python",
        "name": "cell49",
        "codeCollapsed": false
      },
      "source": "# Extracting specific columns (swir22, NDMI, MNDWI, pet) from the validation dataset\nsubmission_val_data=val_data.loc[:,['swir22','NDMI','MNDWI','pet']]\ndisplay(submission_val_data.head())",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1dd61d4f-79a9-4334-a638-4686797777bb",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "MY CODE: PREDICTION FEATURES"
    },
    {
      "id": "3e0f3edd-b21b-4ec0-a301-993747f9517d",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Features para predecir\nX_sub = sub_feat[FEATURES]",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "d7b033c7-3d5f-4179-b8f8-182f8caad0dc",
      "metadata": {
        "language": "python",
        "name": "cell50",
        "codeCollapsed": false
      },
      "source": "submission_val_data.shape",
      "outputs": [],
      "execution_count": 19
    },
    {
      "id": "993d02c3-0a58-40c5-8553-37e309899b07",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "MY CODE: PREDICTION"
    },
    {
      "id": "1e0784b6-d8a1-4049-b108-2bff72cc11ed",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "X_sub_scaled_TA = scaler_TA.transform(X_sub)\npred_TA_submission = model_TA.predict(X_sub_scaled_TA)\n\nX_sub_scaled_EC = scaler_EC.transform(X_sub)\npred_EC_submission = model_EC.predict(X_sub_scaled_EC)\n\nX_sub_scaled_DRP = scaler_DRP.transform(X_sub)\npred_DRP_submission = model_DRP.predict(X_sub_scaled_DRP)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "87b59132-ff14-421e-b37b-472a0adcd9da",
      "metadata": {
        "language": "python",
        "name": "cell51",
        "codeCollapsed": false
      },
      "source": "# --- Predicting for Total Alkalinity ---\nX_sub_scaled_TA = scaler_TA.transform(submission_val_data)\npred_TA_submission = model_TA.predict(X_sub_scaled_TA)\n\n# --- Predicting for Electrical Conductance ---\nX_sub_scaled_EC = scaler_EC.transform(submission_val_data)\npred_EC_submission = model_EC.predict(X_sub_scaled_EC)\n\n# --- Predicting for Dissolved Reactive Phosphorus ---\nX_sub_scaled_DRP = scaler_DRP.transform(submission_val_data)\npred_DRP_submission = model_DRP.predict(X_sub_scaled_DRP)",
      "outputs": [],
      "execution_count": 20
    },
    {
      "id": "473a8b7e-1d24-496f-983a-97f417828e4e",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "MY CODE: SUBMISSION DF"
    },
    {
      "id": "dacde7fe-0ad9-4a24-890f-5e09f9a676ad",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import hashlib\nimport pandas as pd\n\ndef make_point_id(lat, lon, sample_date):\n    lat_r = round(float(lat), 5)\n    lon_r = round(float(lon), 5)\n    d = pd.to_datetime(sample_date).date()\n    raw = f\"{lat_r}|{lon_r}|{d}\"\n    return hashlib.sha256(raw.encode(\"utf-8\")).hexdigest()\n\nsub_template = sub_template.copy()\nsub_template[\"POINT_ID\"] = sub_template.apply(\n    lambda r: make_point_id(r[\"LATITUDE\"], r[\"LONGITUDE\"], r[\"SAMPLE_DATE\"]),\n    axis=1\n)\n\npreds = pd.DataFrame({\n    \"POINT_ID\": sub_feat[\"POINT_ID\"],\n    \"TOTAL_ALKALINITY\": pred_TA_submission,\n    \"ELECTRICAL_CONDUCTANCE\": pred_EC_submission,\n    \"DISSOLVED_REACTIVE_PHOSPHORUS\": pred_DRP_submission\n})\n\nfinal = sub_template.merge(preds, on=\"POINT_ID\", how=\"left\")\n\nsubmission_df = pd.DataFrame({\n    \"Longitude\": final[\"LONGITUDE\"].values,\n    \"Latitude\": final[\"LATITUDE\"].values,\n    \"Sample Date\": final[\"SAMPLE_DATE\"].values,\n    \"Total Alkalinity\": final[\"TOTAL_ALKALINITY\"].values,\n    \"Electrical Conductance\": final[\"ELECTRICAL_CONDUCTANCE\"].values,\n    \"Dissolved Reactive Phosphorus\": final[\"DISSOLVED_REACTIVE_PHOSPHORUS\"].values\n})\n\ndisplay(submission_df.head())",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "398e375c-60cc-4fa5-a697-ae12fdab300c",
      "metadata": {
        "language": "python",
        "name": "cell52",
        "codeCollapsed": false
      },
      "source": "submission_df = pd.DataFrame({\n    'Longitude': test_file['Longitude'].values,\n    'Latitude': test_file['Latitude'].values,\n    'Sample Date': test_file['Sample Date'].values,\n    'Total Alkalinity': pred_TA_submission,\n    'Electrical Conductance': pred_EC_submission,\n    'Dissolved Reactive Phosphorus': pred_DRP_submission\n})",
      "outputs": [],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "id": "46e1c4fa-e49f-40cf-ac10-729b82c4b37b",
      "metadata": {
        "language": "python",
        "name": "cell53",
        "codeCollapsed": false
      },
      "source": "#Displaying the sample submission dataframe\ndisplay(submission_df.head())",
      "outputs": [],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "id": "0d3a8c41-dba2-43e4-b84c-a50a096980e7",
      "metadata": {
        "language": "python",
        "name": "cell54",
        "codeCollapsed": false
      },
      "source": "#Dumping the predictions into a csv file.\nsubmission_df.to_csv(\"/tmp/submission.csv\",index = False)",
      "outputs": [],
      "execution_count": 23
    },
    {
      "cell_type": "code",
      "id": "6bc2ba55-0dd6-43ab-902d-6adbfdfaca2c",
      "metadata": {
        "language": "python"
      },
      "source": "session.sql(f\"\"\"\n    PUT file:///tmp/submission.csv\n    snow://workspace/USER$.PUBLIC.DEFAULT$/versions/live/\n    AUTO_COMPRESS=FALSE\n    OVERWRITE=TRUE\n\"\"\").collect()\n\nprint(\"File saved! Refresh the browser to see the files in the sidebar\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "9b7af545-7a55-4b59-9edc-bc43f47bffd5",
      "metadata": {
        "name": "cell55",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Upload submission file on platform\n\nUpload the `submission.csv` file on the challenge platform to generate your score on the leaderboard."
    },
    {
      "cell_type": "markdown",
      "id": "b7ab09ba-3b69-4a2a-a56e-2dbf084e0c56",
      "metadata": {
        "name": "cell57",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Conclusion\n\nNow that you have learned a basic approach to model training, it’s time to explore your own techniques and ideas! Feel free to modify any of the functions presented in this notebook to experiment with alternative preprocessing steps, feature engineering strategies, or machine learning algorithms. \n\nWe look forward to seeing your enhanced model and the insights you uncover. Best of luck with the challenge!"
    }
  ]
}